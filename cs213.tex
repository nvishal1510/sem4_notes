\documentclass{article}
\title{CS 213 - Data Structures and Algorithms}
\author{Vishal Neeli}
\date{}

\usepackage[a4paper, total={6in, 11in}]{geometry}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{physics}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{mathtools}
\hypersetup{
	colorlinks=true,
	urlcolor=blue,
	linkcolor=cyan,
	filecolor=red
}
\newtheorem*{theorem}{Theorem}

% FOR CODE
% \usepackage{listings}
% \usepackage{color}

% \definecolor{dkgreen}{rgb}{0,0.6,0}
% \definecolor{gray}{rgb}{0.5,0.5,0.5}
% \definecolor{mauve}{rgb}{0.58,0,0.82}

% \lstset{frame=tb,
%   language=Java,
%   aboveskip=3mm,
%   belowskip=3mm,
%   showstringspaces=false,
%   columns=flexible,
%   basicstyle={\small\ttfamily},
%   numbers=none,
%   numberstyle=\tiny\color{gray},
%   keywordstyle=\color{blue},
%   commentstyle=\color{dkgreen},
%   stringstyle=\color{mauve},
%   breaklines=true,
%   breakatwhitespace=true,
%   tabsize=3
% }

\begin{document}
\maketitle

\section{Recursion}

	\subsection{Design principle}
	\begin{enumerate}
		\item Reduce the problem of size n to a size n-1
		\item Figure out the base case (usually n=0 or 1)
		\item Terminate recursion at the base case. Make sure that every n reaches the base case.

	\end{enumerate}

	\subsection{Parameterization}
	\begin{itemize}
		\item It is consumes extra memory if pass a new array (part of old array copied into this) for recursion. Instead we should pass the indices as the parameters.
		\item In creating recursive methods, it is often useful to define additional functions(or methods) to facilitate recursion.

	\end{itemize}

	\subsection{Tail Recursion}
	\begin{itemize}
		\item Recursion has to maintain function calls on stack that makes it more expensive than iterative methods.
		\item To reduce this extra usage of resources, we can write a algorithm in a tail recursive way i.e, the function should directly return the function call (without any other operations on the result returned by the function call).
	\end{itemize}

\section{Algorithm analysis}
	We primarily compare running time in this course. To analyse algorithms, runtime should be machine independent for which we use 'RAM' model of computation.
	\subsection{RAM model}
	\begin{itemize}
		\item Generic single processor model
		\item Computer supports simple constant time instructions
		\begin{itemize}
			\item Arithmetic ($+,-,\times,/,floor,..$)
			\item Data movement (load, store, copy)
			\item Control (branch, function call)
		\end{itemize}
		\item We assume that the cost (runtime) of all simple instructions is 1
		\item Sequential execution - No concurrent execution
		\item Flat memory model and accessing a memory costs 1 unit.
	\end{itemize}
	\subsection{Asymptotic Notation}
	\begin{itemize}
		\item $\Theta$ notation: Given functions g, we define
		\[\Theta(g(n)) = \{f(n) : \exists \text{ positive constants } c_1,c_2,n_0 \text{ such that } c_1g(n) \leq f(n) \leq c_2g(n), \forall n\geq n_0 \}\]
		g(n) is a asymptotic tight bound for f(n).
		\item O notation: Given functions g, we define
		\[O(g(n)) = \{f(n) : \exists\text{ positive constants }c,n_0 \text{ 	such that }  f(n)\leq cg(n), \forall n\geq n_0 \}\]
		g(n) is a asymptotic upper bound for f(n).
		\item $\Omega$ notation: Given functions g, we define
		\[\Omega(g(n)) = \{f(n) : \exists\text{ positive constants }c,n_0 \text{ such that } cg(n)\leq f(n), \forall n\geq n_0\} \]
		g(n) is a asymptotic lower bound for f(n).
	\end{itemize}

\section{Divide and Conquer}
\begin{itemize}
	\item Divide and conquer algorithm is recursive in nature. Basically, we divide a problem into smaller problems (untill we hit the base case) and combine them to get the solution for larger problem.
	\item  For the time complexity of a divide and conquer algorithm, we can write a recurrence relation
	\begin{equation*}
		T(n) = aT(\frac{n}{b}) + C(n) + D(n)		
	\end{equation*}
	where a = no of subproblems a problem is divided, b = factor by which n is reduced, C(n) and D(n) are the time taken in combine and divide step.
\end{itemize}

\section{Recurrence Relation}
	The recurrence relations of type $T(n) = aT(\frac{n}{b}) + f(n)$ can be solved using the following methods:\\
<<<<<<< Updated upstream
	\begin{enumerate}
		\item \textbf{Plug and chuck} : Keep on substituting in the value of $T(\frac{n}{b})$ in terms of smaller n untill we see a pattern. Pattern can be used to easily get the solution
		\item \textbf{Substitution method} : (This is more like check for your solution) In this method, we first guess the solution and prove that using induction, i.e, substitute the solution for $T(\frac{n}{b})$ and check whether it you can arrive at the proposed relation for $T(n)$
		\item \textbf{Recursion-tree method}: We draw the recursion tree for this method. In the recursion tree, leaves contain the cost for the base case and each node contains the cost for the merge and divide process. We sum all of them to get a solution for the recurrence relation. 
		\item \textbf{Using master theorem}: Some of the recurrence relations encountered while working with algorithms can be solved using -
		\begin{theorem}[The master theorem]
		Let $a\geq 1$, $b>1$ and $f(n)$ be a function, then let $T(n)$ be defined on non-negative integers, then the recurrence relation
		\[T(n) = aT(\frac{n}{b}) + f(n) \] is bound assymptotically in three cases.(If possible, let $f(n)= \Theta(n^d)$)
		\begin{align*}
			T(n) &= \sum_{k=0}^{log_bn} a^k f(\frac{n}{b^k})\\
				&= \sum_{k=0}^{log_bn} a^k (\frac{n}{b^k})^d\\ 
				&= 
			\begin{cases}
			O(n^d) \qquad\text{ if } a<b^d\text{ or }f(n)= \Omega(n^{log_ba+\epsilon})\\
			O(n^d logn) \qquad \text{ if } a=b^d\text{ or }f(n)= \Theta(n^{log_ba})\\
			O(n^{log_ba}) \qquad \text{ if } a>b^d\text{ or }f(n)= O(n^{log_ba-\epsilon})\\
			\end{cases}	
		\end{align*}
		\end{theorem}

		\begin{itemize}
		\item In the first case ($a<b^d\text{ or }f(n)= \Omega(n^{log_ba+\epsilon})$), the work done at the first node dominates the time taken. Hence, total time taken = time taken at first node. Also this means that as the depth increases, the work done at each level decreases. 
		\item In the second case ($a=b^d\text{ or }f(n)= \Theta(n^{log_ba})$), the work done at all levels is equal. Hence, the total time taken = time at initial node $\times$ no of levels.
		\item In the third case ($a>b^d\text{ or }f(n)= O(n^{log_ba-\epsilon})$), the work done at the deepest level dominates the time taken. Hence, total time taken = time taken at the lowest level
		\end{itemize}
=======
	\begin{itemize}
	\item Plug and chuck : Keep on substituting in the value of $T(\frac{n}{b})$ in terms of smaller n untill we see a pattern. Pattern can be used to easily get the solution
	\item Substitution method : (This is more like check for your solution) In this method, we first guess the solution and prove that using induction, i.e, substitute the solution for $T(\frac{n}{b})$ and check whether it you can arrive at the proposed relation for $T(n)$
	\item Recursion-tree method: We draw the recursion tree for this method. In the recursion tree, leaves contain the cost for the base case and each node contains the cost for the merge and divide process. We sum all of them to get a solution for the recurrence relation. 

	\begin{theorem}[The master theorem]
	Let $a\geq 1$, $b>1$ and $f(n)$ be a function, then let $T(n)$ be defined on non-negative integers, then the recurrence relation
	\[T(n) = aT(\frac{n}{b}) + f(n) \] is bound assymptotically in three cases.(If possible, let $f(n)= \Theta(n^d)$)
	\begin{align*}
		T(n) &= \sum_{k=0}^{log_bn} a^k f(\frac{n}{b^k})\\
			&= \sum_{k=0}^{log_bn} a^k (\frac{n}{b^k})^d\\ 
	\end{align*}
			\[\boxed{{T(n)= 
					\begin{cases}
					\Theta(n^{log_ba}) \qquad \text{ if } a>b^d\text{ or }f(n)= O(n^{log_ba-\epsilon})\\
					\Theta(n^d logn) \qquad \text{ if } a=b^d\text{ or }f(n)= \Theta(n^{log_ba})\\
					\Theta(n^d) \qquad\text{ if } a<b^d\text{ or }f(n)= \Omega(n^{log_ba+\epsilon})\\
					\end{cases}}}	\]
	\end{theorem}

	\begin{itemize}
	\item In the first case ($a>b^d\text{ or }f(n)= O(n^{log_ba-\epsilon})$), the work done at the deepest level dominates the time taken. Hence, total time taken = time taken at the lowest level
	\item In the second case ($a=b^d\text{ or }f(n)= \Theta(n^{log_ba})$), the work done at all levels is equal. Hence, the total time taken = time at initial node $\times$ no of levels.
	\item In the third case ($a<b^d\text{ or }f(n)= \Omega(n^{log_ba+\epsilon})$), the work done at the first node dominates the time taken. Hence, total time taken = time taken at first node. Also this means that as the depth increases, the work done at each level decreases. 
	\end{itemize}
>>>>>>> Stashed changes


		\item \textbf{Solving Recurrence relation  of type}:
			\[a_n T_n = b_n T_{n-1} + c_n\]
		Our goal here is make the above equation in the form $T_n - T_{n-1} = c_n$, so that we can solve this by summing all the terms
		\begin{enumerate}
			\item We multiply both the sides by a factor $\sigma_n$ which has the property $\sigma_n b_n = \sigma_{n-1} a_{n-1}$, so $\frac{\sigma_n}{\sigma_{n-1}}= \frac{a_{n-1}}{b_n}$
			\[\sigma_n a_n T_n = \sigma_n b_n T_{n-1} + \sigma_n c_n \]
			\[\sigma_n a_n T_n - \sigma_{n-1} b_{n-1} T_{n-1} = \sigma_n c_n\]
			\item Now we sum all the terms to get,
		\end{enumerate}
		\begin{align*}
			\sigma_n a_n T_n &= \sigma_0 a_0 T_0 + \sum_{k=1}^n c_n \sigma_n\\
					T_n &= \frac{ a_0 \sigma_0 T_0 + \sum_{k=1}^n c_n \sigma_n}{\sigma_n a_n} 
		\end{align*}

		\item \textbf{Solving by generating functions}:
		We will use this technique to get a closed form solution for fibonacci series.
		\begin{enumerate}
		\item Write a single recurrence equation for $g_n$.\\
		In the case of Fibannaci series, it is
			\[g_n = g_{n-1} + g_{n-2} + \delta_1\]
		where $\delta_1$ is the dirac delta function. This is used because we can assume $g_n=0$ for all non positive numbers and still satisfy this for $n=1$.
		\item Multiply both sides by $z^n$ and z transform LHS and RHS.\\
		For fibanacci series, 
		\begin{equation*}
			G(z)= zG(z)+z^2G(z) + z 
		\end{equation*}
		where $G(z)$ is the z transform of $g(z)$
		\item Solve for $G(z)$ in the z domain\\
		For fibanacci series
		\[G(z) = \frac{z}{1-z-z^2}\]
		\item Inverse transform $G(z)$ to get $g(z)$
		\[g_n = \frac{1}{\sqrt{5}}(\phi^n - \bar{\phi}^n)\]
		\end{enumerate}


	\end{enumerate}



















\end{document}